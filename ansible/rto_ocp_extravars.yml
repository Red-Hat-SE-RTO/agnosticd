---
# Variables for Amazon Web Services
guid: rto127

num_users: 10

cloud_provider: ec2

  # ocp4_installer_version: "4.5.40"
ocp4_installer_version: "4.7.13"

worker_instance_count: 2

software_to_deploy: openshift4

# Be sure to put a leading "." in front of the subodmain_base_suffix below
subdomain_base_suffix: .d8b3.sandbox525.opentlc.com
### Route 53 Zone ID (AWS)
# This is the Route53 HostedZoneId where you will create your Public DNS entries
# It needs to match the subdomain_base_suffix above, this will be provided by your rhpds sandbox instance
HostedZoneId: Z07204041A5Z64HEB0222

workshop_che_user_password: 'openshift'
workshop_openshift_user_password: 'openshift'


ocp4_network_type: OpenshiftSDN
ocp4_network_ovn_install_workaround: false

install_ftl: false

env_type: ocp4-cluster

aws_region: us-east-2

cluster_name: "cluster-{{ guid }}"

ocp4_workload_authentication_htpasswd_user_count: 10

ocp4_enable_cluster_shutdown: false

install_student_user: true

ocp4_cluster_show_default_user_info: true
ocp4_cluster_show_flight_check_user_info: "{{ ocp4_cluster_show_default_user_info }}"
ocp4_cluster_show_access_user_info: "{{ ocp4_cluster_show_default_user_info }}"

# Authentication (HT Passwd)
ocp4_workload_authentication_idm_type: htpasswd
ocp4_workload_authentication_admin_user: admin
# When no password specified it is generated
ocp4_workload_authentication_htpasswd_admin_password: "r3dh4t1!"
ocp4_workload_authentication_htpasswd_user_base: user
# When no password specified it is generated
ocp4_workload_authentication_htpasswd_user_password: "openshift"
  # ocp4_workload_authentication.htpasswd_user_password: "openshift"

# Deploy in a Ansible 2.9 Virtualenv

agnosticv_meta:
  virtualenv: aws-ansible-2.9

# Remove the standard kubeadmin user
ocp4_workload_authentication_remove_kubeadmin: true

infra_workloads: 
  - ocp4_workload_authentication
  - ocp4_workload_le_certificates
  # - ocp4_workload_machinesets
  # - ocp4_workload_logging

student_workloads: []

remove_workloads: []

# Authentication (HT Passwd)
ocp4_workload_authentication_idm_type: htpasswd
ocp4_workload_authentication_admin_user: opentlc-mgr
ocp4_workload_authentication_admin_password: 'r3dh4t1!'

rhel_repos_el7:
  - rhel-7-server-ansible-2.9-rpms
  - rhel-7-server-rpms
  - rhel-7-server-extras-rpms
  - rhel-7-server-optional-rpms

purpose: development

ocp4_installer_root_url: http://d3s3zqyaz8cp2d.cloudfront.net/pub/openshift-v4/clients

install_ocp4: true


# -------------------------------------------------------------------
# AWS Infrastructure
# -------------------------------------------------------------------

# See cloud_providers/ec2_default_vars.yml
# See roles-infra/infra-ec2-project-create/defaults/main.yml

platform: labs

# The availability Zones for which to create worker MachineSets for.
# Leave empty for the default (set up one MachineSet for
# each availability zone).
# Set to 5 entries or less for deployment in Sandboxes (each MachineSet needs an EIP
# and Sandboxes only have 5 EIPs available).
openshift_machineset_aws_zones: []
# openshift_machineset_aws_zones:
# - us-east-1a
# - us-east-1b
# - us-east-1c

# -------------------------------------------------------------------
# AWS EC2 Instances
# -------------------------------------------------------------------

# Bastion Configuration
bastion_instance_type: "t3a.medium"
bastion_instance_image: RHEL77GOLD
# bastion_instance_platform: Linux/UNIX
# bastion_instance_platform: "Red Hat Enterprise Linux" 
# For standard (not GOLD) RHEL images:
# bastion_instance_platform: Red Hat Enterprise Linux
# used for on-demand capacity reservation:
bastion_instance_platform: >-
  {%- if 'RHEL' in bastion_instance_image -%}
  {%-   if 'GOLD' in bastion_instance_image -%}
  Linux/UNIX
  {%-   else -%}
  Red Hat Enterprise Linux
  {%-   endif -%}
  {%- else -%}
  Linux/UNIX
  {%- endif -%}

# Masters

master_instance_type_family: m5a
master_instance_type_size: >-
  {{ 'xlarge' if worker_instance_count|int <= 10
  else '2xlarge' if worker_instance_count|int <= 20
  else '4xlarge'
  }}
master_instance_type: "{{ master_instance_type_family }}.{{ master_instance_type_size }}"

master_instance_count: 3
master_storage_type: >-
  {{ 'io1' if worker_instance_count|int >= 10
  else 'gp2' }}

# When master_storage_type is io1 or io2, you can set the IOPS.
# You usually want to leave it as the default IOPS value is calculated in the role host-ocp4-installer
# master_storage_iops: 2000

worker_instance_type: "m5a.4xlarge"
worker_storage_type: "gp2"

set_env_authorized_key: true
env_authorized_key: "{{guid}}key"
key_name: "openshiftkey"         # Instances to be provisioned

student_name: user
install_bastion: true

repo_method: rhn

install_common: true
update_packages: true
# Provide these as a list.
# Each instance type can have any number of replicas deployed with the same
# configuration.
# Metadata in OpenStack is equivelent to tags in AWS
# These instances will be created with Cinder persistent volumes
instances:
- name: "bastion"
#  count: "{{ bastion_instance_count}}"
#  unique: "{{ true if clientvm_instance_count | int <= 1 else false }}"
  count: 1
  unique: true
  public_dns: true
  alt_name:
  - clientvm
  image: "{{ bastion_instance_image }}"
  flavor:
    "ec2": "{{ bastion_instance_type }}"
  tags:
  - key: "AnsibleGroup"
    value: "bastions,clientvms"
  - key: "ostype"
    value: "linux"
  - key: "Purpose"
    value: "{{ purpose }}"
  - key: "project"
    value: "{{ project_tag }}"
  - key: "user"
    value: "{{ student_name }}"
  rootfs_size: "{{ bastion_rootfs_size }}"
  security_groups:
  - BastionSG

# -------------------------------------------------------------------
# AWS On-demand Capacity
# -------------------------------------------------------------------
# To disable ODCR entirely, just set the following variable to false:
#agnosticd_aws_capacity_reservation_enable: false

######################################
# ocp4-cluster for workshops and labs
######################################
# This ODCR config is the one that has the most chances to successfully deploy.
# It has very few constraints and the goal is to avoid Insufficient
# Instance Capacity errors.
#
# - Workers are split on 2 zones, if possible. Can be a single zone.
# - Masters are all in the same zone.
# - Bastion has its own zone, which can also be the same as the other zones,
#   because we don't request zones to be distinct.
# Zones can be the same, not necessarly distinct.
agnosticd_aws_capacity_reservation_distinct: false
agnosticd_aws_capacity_reservations:
  # Bastion can have its own AZ
  az1:
  - instance_type: "{{ bastion_instance_type }}"
    instance_count: 1
    instance_platform: "{{ bastion_instance_platform }}"

  masters:
  - instance_type: "{{ master_instance_type }}"
    instance_count: 3
    instance_platform: Linux/UNIX

  # Split workers in 2 AZs if possible.  Could be the same zone.
  workers1:
  # Workers: half of workers
  - instance_type: "{{ worker_instance_type }}"
    instance_count: >-
      {{ ( worker_instance_count | int / 2 )
      | round(0, 'ceil')
      | int }}
    instance_platform: Linux/UNIX
  workers2:
  - instance_type: "{{ worker_instance_type }}"
    instance_count: >-
      {{ ( worker_instance_count | int / 2 )
      | round(0, 'ceil')
      | int }}
    instance_platform: Linux/UNIX
